# Rate Limiter System

## Why do we need it?
- To protect from dos attack
- Ensures servers are not overburdened
- Prevents resource starvation/abuse
- Control consumption cost


## Ways of Throttling
- Slow down the call
- Reject API
- Ignore API


## Example
- API Gateway includes a feature where we can rate limit and throttle API requests


## External Rate Limiter vs Attached Rate Limiter
- Can be scaled independently || tightly coupled
- Requires Additional hardware || no additional infrastructure
- Includes performance overhead by adding a new call || Lower latency since it is integrated with the service

## Questions ->
1. Fixed Window or Sliding Window?
2. Client or Server??
=> It will be Server side in most case
3. What should happen if limit is reached?
=> Some meaningful message should be sent to users

## Functional Requirements
1. Identify requests by IP address or User Id
2. Fixed window or Sliding window
3. Minimal effect on HTTP response time
4. Server side rate limiting
5. Provide feedback to API 

## Non-Functional Requirements
1. Highly Available
2. Minimal latency
3. Scalable

## Where rate limiter should be between APIs?
1- Stand Alone Service 
Client will first hit the rate limiter service, which will route to the API servers or send error.
- More HTTP calls will add to latency
- Will become bottle neck for services
- Will become single point of failure
- Resource allocation done for this


2. Put the logic in the API server
- Rate limiting logic will be duplicated

3. Putting Rate Limiter logic in API Gateway, Reverse Proxy or Load Balancer
This seems ideal as we have logic embedded in existing server and we are not having to duplicate it.

## Data for Rate limiter
- IP Address or UserId
- Number of requests in last N minutes
- Timestamp of latest request per IO/userId

## Table Schema
{userId, timeStamp, isSuccess} All Requests will be stored here

Rate limiter will be connected to a data store
We can use Sql database or a Cache to store data
If we want low latency and built-in TTL then choose Redis
If we want to store data for auditing, reporting then choose MySql


Problems ->
- Since we are saving one row for each request, this database will soon have millions of records
- Query and Computation will be very slow and will consume lots of db cycles.

Since we want temporary storage only and fast access. We will use Cache.


So System will look like this

User ----> API Gateway (Rate Limiter Integrated)  -----> API Service 
              Or          |
          Load Balancer   |
                          v
                        Cache
  
## User Feedback
We will send user the code 429 (Too many requests)
We can also add a header
Retry-After : X.xy seconds

